# -*- coding: utf-8 -*-
"""chatbot prompted.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sq978Gat_6Zp2wzgelLY1V_spG_ZpQSI
"""

!pip install transformers==4.37.0 autoawq==0.2.3 torch==2.2.0

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import re

# Load the model and tokenizer
model_name = "TheBloke/Mistral-7B-Instruct-v0.2-AWQ"
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", trust_remote_code=False)
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=False)

# Create a text-generation pipeline
pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=4096,
    do_sample=True,
    temperature=0.7,
    top_p=0.95,
    top_k=40,
    repetition_penalty=1.1
)

def get_output(input_text):
    prompt_template = f'''<s>[INST] {input_text} [/INST]'''
    tokens = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()
    pipe_output = pipe(prompt_template)[0]['generated_text']
    return pipe_output

def is_itinerary_request(user_input):
    # Define keywords related to itinerary requests
    itinerary_keywords = ['itinerary', 'plan', 'schedule', 'trip plan', 'travel plan']
    return any(re.search(rf'\b{word}\b', user_input.lower()) for word in itinerary_keywords)

def travel_chatbot():
    print("Welcome to the Tours and Travel Chatbot!")
    print("How can I assist you with your travel plans today?")
    print("(Type 'exit' to end the conversation)")

    while True:
        user_input = input("You: ").strip()

        if user_input.lower() == 'exit':
            print("Thank you for using our Tours and Travel Chatbot. Have a great day!")
            break

        # Check if the user is asking for an itinerary or plan
        if is_itinerary_request(user_input):
            print("Chatbot: For detailed itinerary planning or trip schedules, please visit our main page, where you can generate custom itineraries.")
            continue

        # Prepare the prompt for the travel context
        travel_prompt = f"You are a helpful tours and travel assistant. Provide information and suggestions related to travel. User query: {user_input}"

        # Get the model's response
        response = get_output(travel_prompt)

        # Extract the relevant part of the response (after the instruction)
        response_parts = response.split("[/INST]")
        if len(response_parts) > 1:
            cleaned_response = response_parts[1].strip()
        else:
            cleaned_response = response.strip()

        print("Chatbot:", cleaned_response)

if __name__ == "__main__":
    travel_chatbot()

